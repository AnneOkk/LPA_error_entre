---
title: "LPA_Errorstudy"
author: "Anne"
date: "3/18/2021"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '1'
lang: en-US
editor_options: 
  chunk_output_type: inline
  fig_caption: yes
  fig_width: 4 
  fig_height: 4 
---

# Preparation

## Get data

```{r loading_packs, eval = FALSE, cache = TRUE, include = F, echo = F}
knitr::opts_chunk$set(include = T, echo = F, warning = F, message = F,  results = "hide")
                      
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("mediation", "foreign", "tidyverse","stargazer","multicon", "ggplot2", "plyr", "reshape2", "readxl", 
              "scales", "grid", "tidyLPA", "Rcpp", "naniar", "dplyr", "car", "mice", "semTools",
              "rstudioapi", "labelled", "modi", "semPlot", "kulife", "interactions", "emmeans")
ipak(packages)
```

```{r setwd, eval = F, include = FALSE, echo = FALSE}
library(rstudioapi)
 set_wd <- function() {
   current_path <- getActiveDocumentContext()$path 
   setwd(dirname(current_path ))
   print( getwd() )
 }
 set_wd()
```

```{r loading_data, include = F}
library(rlang)
library(tidyverse)
library(foreign)
library(readxl)
options(knitr.table.format = function() {
  if (knitr::is_latex_output()) 'latex' else 'pandoc'
})

library(haven)

files <- dir(getwd(), pattern = "\\.sav$", full.names = FALSE) 
files
df_list <- vector("list", length(files))
names(df_list) <- files
read_in <- function(df = files) {
  for (fname in df) {
    df_list[[fname]] <- read_sav(fname) 
  }
    names(df_list) <- paste0("data_", gsub(".sav","",names(df_list)))
    ff <- df_list
}

df_list <- read_in(files)

list2env(df_list,envir=.GlobalEnv)


files <- dir(getwd(), pattern = "\\.xlsx$", full.names = FALSE) 
files
df_list <- vector("list", length(files))
names(df_list) <- files
read_in <- function(df = files) {
  for (fname in df) {
    df_list[[fname]] <- read_excel(fname) 
  }
    names(df_list) <- paste0("data_", gsub(".xlsx","",names(df_list)))
    ff <- df_list
}

df_list <- read_in(files)
list2env(df_list,envir=.GlobalEnv)
```

```{r left_join, include = F}
## left join

library(tidyverse)
# First data set 
IP_ID <- data_datasetT1T2_match %>% dplyr::select(IPAddress, T2ID)
T1 = left_join(IP_ID, data_T1,  by="IPAddress", all = TRUE) %>% dplyr::rename(T1duration = Duration__in_seconds_)
T1T2 <- left_join(T1, data_T2, by = "T2ID") %>% dplyr::rename(T2duration = Duration__in_seconds_)
T1T2T3 <- left_join(T1T2, data_T3, c("T2ID" = "PROLIFIC_PID")) %>% dplyr::rename(T3duration = Duration__in_seconds_)
T1T2T3T4 <- left_join(T1T2T3, data_T4, c("T2ID" = "PROLIFIC_PID")) %>% 
  dplyr::rename(T1ID = T2ID,
                T4duration = Duration__in_seconds_) 

names(T1T2T3T4) <- gsub("Q675", "T4Gopro", names(T1T2T3T4)) %>%
  gsub("Q676", "T4Thriv", .)

# Second data set 
df_Presel <- data_Presel %>% dplyr::select(T1ID = PROLIFIC_PID, 
                              T1octyp = PREoctyp,
                              T1found = PREfound, 
                              T1date_7 = PREdate_7,
                              T1date_8 = PREdate_8,
                              T1inno_1 = PREinno_1,
                              T1inno_3 = PREinno_3,
                              T1inno_4 = PREinno_4,
                              T1inno_6 = PREinno_6,
                              T1inno_10 = PREinno_10,
                              T1inno_4_TEXT = PREinno_4_TEXT,
                              )

T1Pre = left_join(data_T1_2, df_Presel,  c("PROLIFIC_PID" = "T1ID"), all = TRUE) %>% dplyr::rename(T1duration = Duration__in_seconds_)
T1T2_2 = left_join(T1Pre, data_T2_2,  by="PROLIFIC_PID", all = TRUE) %>% dplyr::rename(T2duration = Duration__in_seconds_)
T1T2T3_2 = left_join(T1T2_2, data_T3_2,  by="PROLIFIC_PID", all = TRUE) %>% dplyr::rename(T3duration = Duration__in_seconds_)
T1T2T3T4_2 = left_join(T1T2T3_2, data_T4_2,  c("PROLIFIC_PID" = "T4ID"), all = TRUE) %>% dplyr::rename(T4duration = Duration__in_seconds_)
```

```{r recode_wrong, include = F}
library(sjlabelled)
T1T2T3T4 <- T1T2T3T4 %>% remove_all_labels(.) %>%
  mutate_at(vars(matches("T1octypp")), funs(dplyr::recode(.,`1` = 1, `2` = 2, `4`=3, `5`=4, `6` = 5, .default = NULL))) %>%
  mutate_at(vars(matches("T1brex")), funs(dplyr::recode(., `23`=1, `24`=2, `25` = 3,`26` = 4,`27` = 5, .default = NULL))) %>%
  mutate_at(vars(matches("T1errund")), funs(dplyr::recode(., `6`=2, `2` = 3,`7` = 4,`8` = 5, .default = NULL))) %>%
  mutate_at(vars(matches("T1chal")), funs(dplyr::recode(.,`14`=1, `15`=2, `16` = 3,`17` = 4,`18` = 5, `19`=6, `20`=7, .default = NULL))) %>%
  mutate_at(vars(matches("T1threat")), funs(dplyr::recode(.,`14`=1, `15`=2, `16` = 3,`17` = 4,`18` = 5, `19`=6, `20`=7, .default = NULL))) %>%
  mutate_at(vars(matches("T1hindr")), funs(dplyr::recode(.,`14`=1, `15`=2, `16` = 3,`17` = 4,`18` = 5, `19`=6, `20`=7, .default = NULL))) %>%
  mutate_at(vars(matches("T1accri")), funs(dplyr::recode(.,`13`=1, `14`=2, `15` = 3,`16` = 4,`17` = 5, `18`=6, `19`=7, .default = NULL))) %>%
  mutate_at(vars(matches("T1exploi")), funs(dplyr::recode(.,`1`=1, `25`=2, `26` = 3,`27` = 4,`28` = 5, `30`=6, `31`=7, .default = NULL))) %>%
  mutate_at(vars(matches("T1explor")), funs(dplyr::recode(.,`1`=1, `24`=2, `25` = 3,`26` = 4,`27` = 5, `28`=6, `29`=7, .default = NULL))) %>%
  mutate_at(vars(matches("T1BIS")), funs(dplyr::recode(.,`22`=1, `23`=2, `24` = 3,`25` = 4,`26` = 5, `27`=6, `28`=7, .default = NULL))) %>%
  mutate_at(vars(matches("T1BAS1")), funs(dplyr::recode(.,`22`=1, `23`=2, `24` = 3,`25` = 4,`26` = 5, `27`=6, `28`=7, .default = NULL))) %>%
  mutate_at(vars(matches("T1BAS2")), funs(dplyr::recode(.,`22`=1, `23`=2, `24` = 3,`25` = 4,`26` = 5, `27`=6, `28`=7, .default = NULL)))  %>%
  mutate_at(vars(matches("T1sex")), funs(dplyr::recode(.,`1`=1, `2`=2, `4` = 3, .default = NULL))) %>%
  mutate_at(vars(matches("T1lang")), funs(dplyr::recode(.,`1`=1, `2`=2, `4` = 3, .default = NULL))) %>%
  mutate_at(vars(matches("T1chin")), funs(dplyr::recode(.,`1`=1, `2`=2, `3`=3,`4` = 4,`6` = 5, .default = NULL)))

```

```{r bind, include = F}
library(plyr)
df <- plyr::rbind.fill(T1T2T3T4, T1T2T3T4_2)
## delete duplicates 
df = df[!duplicated(df$T1ID),]

names(df) <- tolower(names(df))
df_demo <- df %>% dplyr::select(matches("t.duration|t1octyp|t1octyp.|t1expt_7|t1senr|t1found|t1date_7|t1date_8|t1inno|t1owner|t1coown|t1coownn_4|t1perown_1|t1func|t1mbus|t1mbusn_1|t1indu|t1prod|t1opnec|t1count|t1age_4|t1sex|t1lang|t1edu|t1child|t1chin|t2emp|t2empn_1|t2act.|t2sumcap|t2capit|t2how_.|t2hod_.|t4_fundr|t4_fundr.|t1brex"))

error_df <- df %>% dplyr::select(matches("T1ID|t.error|t.errser_.|t.errsel|t.errper_.|t.errpre_.|t.errund_."))
  
df_scales <- df %>% dplyr::select(matches("T1ID|t.chal_.|t.threat_.|t.hindr_.|t.accri_.|t.exploi_.|t.explor_.|t.bis_.|t.bas._.|t.gopro_.|t.thriv_.|t4envdyn_."))
```

## Attention check

```{r rename_att, include = F}
## attention check items

# attention check items 
df_rename_att <- df_scales %>% cbind(., df_demo) %>%
  dplyr::rename(
    att_1_t1 = t1chal_2,
    att_2_t1 = t1accri_4,
    att_3_t1 = t1thriv_7,
    att_1_t2 = t2chal_2,
    att_2_t2 = t2accri_4,
    att_3_t2 = t2thriv_7,
    att_1_t3 = t3chal_2,
    att_2_t3 = t3accri_4,
    att_3_t3 = t3thriv_7,
    att_1_t4 = t4chal_2,
    att_2_t4 = t4accri_4,
    att_3_t4 = t4thriv_7)

## create attention fails df 
att_1_t1 <- df_rename_att[df_rename_att$att_1_t1 %in% c(1, 2, 3,4,6,7), ]
att_2_t1 <- df_rename_att[df_rename_att$att_2_t1 %in% c(1, 3, 4, 5, 6,7), ]
att_3_t1 <- df_rename_att[df_rename_att$att_3_t1 %in% c(1, 2, 3, 4, 5,7), ]
att_1_t2 <- df_rename_att[df_rename_att$att_1_t2 %in% c(1, 2, 3,4,6,7), ]
att_2_t2 <- df_rename_att[df_rename_att$att_2_t2 %in% c(1, 3, 4, 5, 6,7), ]
att_3_t2 <- df_rename_att[df_rename_att$att_3_t2 %in% c(1, 2, 3, 4, 5,7), ]
att_1_t3 <- df_rename_att[df_rename_att$att_1_t3 %in% c(1, 2, 3,4,6,7), ]
att_2_t3 <- df_rename_att[df_rename_att$att_2_t3 %in% c(1, 3, 4, 5, 6,7), ]
att_3_t3 <- df_rename_att[df_rename_att$att_3_t3 %in% c(1, 2, 3, 4, 5,7), ]
att_1_t4 <- df_rename_att[df_rename_att$att_1_t4 %in% c(1, 2, 3,4,6,7), ]
att_2_t4 <- df_rename_att[df_rename_att$att_2_t4 %in% c(1, 3, 4, 5, 6,7), ]
att_3_t4 <- df_rename_att[df_rename_att$att_3_t4 %in% c(1, 2, 3, 4, 5,7), ]


attention_fail <- rbind(att_1_t1, att_2_t1,att_3_t1,
                        att_1_t2, att_2_t2, att_3_t2, 
                        att_1_t3,att_2_t3,att_3_t3,
                        att_1_t4,att_2_t4,att_3_t4) %>%
  as_tibble(.)

ID_vals <- data.frame(table(attention_fail$t1id))
Rows_fails <- attention_fail$t1id %in% ID_vals[ID_vals$Freq > 1,1]
Att_fails <- attention_fail[Rows_fails,]

## Number of fails
(data.frame(table(Att_fails$t1id)))

## exclude attention fails (two or more fails)
df_att <- df_rename_att[!(df_rename_att$t1id %in% Att_fails$t1id),]

# create attention check variable
att_check = df_rename_att %>% dplyr::select(att_1_t1,att_2_t1, att_3_t1,
                                            att_1_t2,att_2_t2,att_3_t2,
                                   att_1_t3,att_2_t3,att_3_t3,
                                   att_1_t4,att_2_t4,att_3_t4)

df_scales <- df_att %>% dplyr::select(-matches("att_._t."))

## rename items after attention check
df_scales <- df_scales %>% dplyr::rename(
  t1chal_2 = t1chal_3,
  t1chal_3 = t1chal_4,
  t1accri_4 = t1accri_5,
  t1accri_5 = t1accri_6,
  t1accri_6 = t1accri_7,
  t1thriv_7 = t1thriv_8,
  t1thriv_8 = t1thriv_9,
  t1thriv_9 = t1thriv_10,
  t1thriv_10 = t1thriv_11,
  t2chal_2 = t2chal_3,
  t2chal_3 = t2chal_4,
  t2accri_4 = t2accri_5,
  t2accri_5 = t2accri_6,
  t2accri_6 = t2accri_7,
  t2thriv_7 = t2thriv_8,
  t2thriv_8 = t2thriv_9,
  t2thriv_9 = t2thriv_10,
  t2thriv_10 = t2thriv_11,
  t3chal_2 = t3chal_3,
  t3chal_3 = t3chal_4,
  t3accri_4 = t3accri_5,
  t3accri_5 = t3accri_6,
  t3accri_6 = t3accri_7,
  t3thriv_7 = t3thriv_8,
  t3thriv_8 = t3thriv_9,
  t3thriv_9 = t3thriv_10,
  t3thriv_10 = t3thriv_11,
  t4chal_2 = t4chal_3,
  t4chal_3 = t4chal_4,
  t4accri_4 = t4accri_5,
  t4accri_5 = t4accri_6,
  t4accri_6 = t4accri_7,
  t4thriv_7 = t4thriv_8,
  t4thriv_8 = t4thriv_9,
  t4thriv_9 = t4thriv_10,
  t4thriv_10 = t4thriv_11,
)
```

## Recode

```{r}
df_scales <-
df_scales %>%
mutate_at(vars(c("t1accri_2", "t1bis_4", "t1bis_6", "t1thriv_4","t1thriv_10",
                 "t2accri_2","t2thriv_4","t2thriv_10",
                 "t3accri_2","t3thriv_4","t3thriv_10",
                 "t4accri_2", "t1bis_4", "t4bis_6", "t4thriv_4", "t4thriv_10",
                 "t4envdyn_4")),
            ~ (8 - .))

df_scales <-
df_scales %>%
mutate_at(vars(c("t1gopro_2", "t1gopro_4",
                 "t2gopro_2", "t2gopro_4",
                 "t3gopro_2", "t3gopro_4",
                 "t4gopro_2", "t4gopro_4")),
            ~ (6 - .))

# delete double bas item
df_scales <- df_scales %>% dplyr::select(-matches("t1bas2_1"))
```

## Rename

```{r rename, include = F}
names(df_scales) <- gsub("bas1_1", "basre_1", names(df_scales))
names(df_scales) <- gsub("bas1_2", "basre_2", names(df_scales))
names(df_scales) <- gsub("bas1_3", "basre_3", names(df_scales))
names(df_scales) <- gsub("bas1_4", "basre_4", names(df_scales))
names(df_scales) <- gsub("bas1_5", "basre_5", names(df_scales))
names(df_scales) <- gsub("bas1_6", "basdr_1", names(df_scales))
names(df_scales) <- gsub("bas1_7", "basdr_2", names(df_scales))

names(df_scales) <- gsub("t1bas2_2", "t1basdr_3", names(df_scales))
names(df_scales) <- gsub("t1bas2_3", "t1basdr_4", names(df_scales))
names(df_scales) <- gsub("t1bas2_4", "t1basfu_1", names(df_scales))
names(df_scales) <- gsub("t1bas2_5", "t1basfu_2", names(df_scales))
names(df_scales) <- gsub("t1bas2_6", "t1basfu_3", names(df_scales))
names(df_scales) <- gsub("t1bas2_7", "t1basfu_4", names(df_scales))

names(df_scales) <- gsub("bas2_1", "basdr_3", names(df_scales))
names(df_scales) <- gsub("bas2_2", "basdr_4", names(df_scales))
names(df_scales) <- gsub("bas2_3", "basfu_1", names(df_scales))
names(df_scales) <- gsub("bas2_4", "basfu_2", names(df_scales))
names(df_scales) <- gsub("bas2_5", "basfu_3", names(df_scales))
names(df_scales) <- gsub("bas2_6", "basfu_4", names(df_scales))

vita_lean_df <- df_scales %>% dplyr::select(matches("thriv"))
names(vita_lean_df) <- gsub("thriv_10", "vita_5", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_1", "learn_1", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_2", "learn_2", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_3", "learn_3", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_4", "learn_4", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_5", "learn_5", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_6", "vita_1", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_7", "vita_2", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_8", "vita_3", names(vita_lean_df))
names(vita_lean_df) <- gsub("thriv_9", "vita_4", names(vita_lean_df))

df_scales <- cbind(df_scales, vita_lean_df)

names(df_scales) <- gsub("t4_fundr", "t4fundr", names(df_scales))
names(df_scales) <- gsub("t4_fundr2", "t4fundr2", names(df_scales))

```

```{r demo_recode, include = F}
## Demos dataframe

## time since business foundation 
library(zoo)
library(lubridate)
df_scales$t1timebuiss <- as.yearmon(paste(df_scales$t1date_7, df_scales$t1date_8), "%Y %m")
df_scales$t1timebuiss <- as_date(df_scales$t1timebuiss)
df_scales$start_t1 <- as.Date("2019-11-15")

df_scales$t1timebuiss <- difftime(df_scales$start_t1, df_scales$t1timebuiss, UTC,
         units = c("days"))

df_scales$t1timebuiss[ df_scales$t1timebuiss > 18250 ] <- NA
df_scales <- df_scales %>% dplyr::select(-matches("t1date"))

## innovativeness 
df_scales$t1innosum <- df_scales %>% dplyr::select(matches("inno")) %>%
   mutate(t1innosum = rowSums(subset(., select = c(t1inno_1:t1inno_4)), na.rm = T)) %>% dplyr::select(matches("t1innosum")) %>% .[["t1innosum"]]

df_scales <- df_scales %>% dplyr::select(-matches("t1inno_"))

## recode occupational function
df_scales$t1func[df_scales$t1func_5_text == "president/CEO"] = 1
df_scales$t1func[df_scales$t1func_5_text == "Finance director"] = 1
df_scales$t1func[df_scales$t1func_5_text == "CFO"] = 1
df_scales$t1func[df_scales$t1func_5_text == "Creative Director"] = 2
df_scales <- df_scales %>% dplyr::select(-matches("t1func_5_text"))

## recode industry
df_scales$t1indu[df_scales$t1indu_7_text == "HR"] = 2

df_scales$t1indu[df_scales$t1indu_7_text == "Personal Services"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "governance"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "Dog walking"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "Self-Improvement"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "Event planning"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "Hospitality, guest house"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "Services"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "Pet Services"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "Consultancy"] = 3
df_scales$t1indu[df_scales$t1indu_7_text == "Beauty"] = 3

df_scales$t1indu[df_scales$t1indu_7_text == "Service customising retail goods"] = 4
df_scales$t1indu[df_scales$t1indu_7_text == "Retail"] = 4

df_scales$t1indu[df_scales$t1indu_7_text == "transport"] = 5

# new category = 8 (Arts, Fashion & Entertainment)
df_scales$t1indu[df_scales$t1indu_7_text == "Entertainment/Music"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "entertainment"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Arts"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Entertainment"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Media"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "FASHION"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "art"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Creative"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Arts"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Creative Arts"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Art"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Art & Entertainment"] = 8
df_scales$t1indu[df_scales$t1indu_7_text == "Design"] = 8

df_scales <- df_scales %>% dplyr::select(-matches("t1indu_7_text"))

## remove language text 
df_scales <- df_scales %>% dplyr::select(-matches("t1lang_4_text"))

## recode education 
df_scales$t1edu[df_scales$t1edu_6_text == "Masters Degree"] = 4
df_scales$t1edu[df_scales$t1edu_6_text == "Masters degree"] = 4
df_scales$t1edu[df_scales$t1edu_6_text == "post grad diploma"] = 4
df_scales$t1edu[df_scales$t1edu_6_text == "Some upper secondary school"] = 2
df_scales$t1edu[df_scales$t1edu_6_text == "MA"] = 4
df_scales$t1edu[df_scales$t1edu_6_text == "A Levels"] = 2
df_scales$t1edu[df_scales$t1edu_6_text == "Master's Degree"] = 4
df_scales$t1edu[df_scales$t1edu_6_text == "masters degree"] = 4
df_scales$t1edu[df_scales$t1edu_6_text == "University Diploma"] = 4
df_scales$t1edu[df_scales$t1edu_6_text == "Masters degree"] = 4
df_scales$t1edu[df_scales$t1edu_6_text == "Technical College"] = 4

df_scales <- df_scales %>% dplyr::select(-matches("t1edu_6_text"))

## recode country 
# 1 = USA
# 2 = UK
# 3 = Canada 
# 4 = Italy
# 5 = Hungary
# 6 = Poland
# 7 = Mexico
# 8 = Portugal
# 9 = Austria
# 10 = Germany
# 11 = Slovenia
# 12 = Netherlands
# 13 = Sweden
# 14 = Czech Republic
# 15 = Malta
# 16 = Greece
# 17 = France
# 18 = Spain
# 19 = Israel
# 20 = Estonia
# 21 = Brazil 
# 22 = Benin
# 23 = Australia
# 24 = Latvia
# 25 = Korea
# 26 = Norway
# 27 = New Zealand
# 28 = United Arab Emirates

df_scales$t1count[df_scales$t1count == 187] = 1
df_scales$t1count[df_scales$t1count == 185] = 2
df_scales$t1count[df_scales$t1count == 31] = 3
df_scales$t1count[df_scales$t1count == 84] = 4
df_scales$t1count[df_scales$t1count == 76] = 5
df_scales$t1count[df_scales$t1count == 137] = 6
df_scales$t1count[df_scales$t1count == 111] = 7
df_scales$t1count[df_scales$t1count == 138] = 8
df_scales$t1count[df_scales$t1count == 10] = 9
df_scales$t1count[df_scales$t1count == 65] = 10
df_scales$t1count[df_scales$t1count == 158] = 11
df_scales$t1count[df_scales$t1count == 122] = 12
df_scales$t1count[df_scales$t1count == 168] = 13
df_scales$t1count[df_scales$t1count == 45] = 14
df_scales$t1count[df_scales$t1count == 107] = 15
df_scales$t1count[df_scales$t1count == 67] = 16
df_scales$t1count[df_scales$t1count == 61] = 17
df_scales$t1count[df_scales$t1count == 163] = 18
df_scales$t1count[df_scales$t1count == 83] = 19
df_scales$t1count[df_scales$t1count == 57] = 20
df_scales$t1count[df_scales$t1count == 24] = 21
df_scales$t1count[df_scales$t1count == 19] = 22
df_scales$t1count[df_scales$t1count == 9] = 23
df_scales$t1count[df_scales$t1count == 94] = 24
df_scales$t1count[df_scales$t1count == 140] = 25
df_scales$t1count[df_scales$t1count == 128] = 26
df_scales$t1count[df_scales$t1count == 123] = 27
df_scales$t1count[df_scales$t1count == 184] = 28

library(plotly)
table(df_scales$t1count, useNA="always")

## remove source money text 
df_scales <- df_scales %>% dplyr::select(-matches("t2capit_8_text"))

## remove lang_text 
df_scales <- df_scales %>% dplyr::select(-matches("t1lang_3_text"))

## make timebuiss numeric 
df_scales$t1timebuiss <- as.numeric(df_scales$t1timebuiss)

## recode occupation past 
# new category: Student = 7
df_scales$t1octypp[df_scales$t1octypp_6_text == "Student"] = 7
df_scales$t1octypp[df_scales$t1octypp_6_text == "student"] = 7
df_scales <- df_scales %>% select(-matches("t1octypp_6_text"))

## remove start_t1
df_scales <- df_scales %>% dplyr::select(-matches("start_t1"))

## remove found (only 1!) 
df_scales <- df_scales %>% dplyr::select(-matches("t1found"))

## demo numeric
df_scales_num <- df_scales %>% dplyr::select(-matches("t1prod|t1id"))

```

# Reliabilities 

```{r}
df_demo_num <- df_scales %>% dplyr::select(matches("t.duration|t1octyp|t1octyp.|t1expt_7|t1senr|t1found|t1date_7|t1date_8|t1inno|t1owner|t1coown|t1coownn_4|t1perown_1|t1func|t1mbus|t1mbusn_1|t1indu|t1opnec|t1count|t1age_4|t1sex|t1lang|t1edu|t1child|t1chin|t2emp|t2empn_1|t2act.|t2sumcap|t2capit|t2how_.|t2hod_.|t4_fundr|t4_fundr.|t1brex|t1timebuiss|t4fundr2")) %>% remove_all_labels(.)

df_scales_new <- df_scales %>% dplyr::select(-matches("t1id|thriv_|t.duration|t1octyp|t1octyp.|t1expt_7|t1senr|t1found|t1date_7|t1date_8|t1inno|t1owner|t1coown|t1coownn_4|t1perown_1|t1func|t1mbus|t1mbusn_1|t1indu|t1prod|t1opnec|t1count|t1age_4|t1sex|t1lang|t1edu|t1child|t4fundr|t1chin|t2emp|t2empn_1|t2act.|t2sumcap|t2capit|t2how_.|t2hod_.|t4_fundr.|t1brex|t1timebuiss|t4fundr2"))
comp_split <- df_scales_new %>% remove_all_labels(.) %>%
  split.default(sub("_.", "", names(df_scales_new))) 

comp <- purrr::map(comp_split, ~ multicon::composite(.x, nomiss = 0.8), data = .x)
alph <- purrr::map(comp_split, ~ psych::alpha(.x), data = .x) %>%
  purrr::map(~ .x$total)

comp_df <- do.call("cbind", comp) %>% cbind(., df_demo_num) %>% remove_all_labels(.)
alph_df <- do.call("rbind", alph) %>% round(., 2)
```


``` {r reliabilities, include = T, echo = F}
# prolific 
alph_df %>%
DT::datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = c('excel', "csv"),
                   pageLength = 20))

```

# Correlations

```{r corr_table, include = F, echo = F}

corstars <-function(x, method=c("pearson", "spearman"), removeTriangle=c("upper", "lower", "none"),
                     result=c("none", "html", "latex")){
    #Compute correlation matrix
    require(Hmisc)
    x <- as.matrix(x)
    correlation_matrix<-rcorr(x, type=method[1])
    R <- correlation_matrix$r # Matrix of correlation coeficients
    p <- correlation_matrix$P # Matrix of p-value 
    
    ## Define notions for significance levels; spacing is important.
    mystars <- ifelse(p < .001, "*** ", ifelse(p < .01, "**  ", ifelse(p < .05, "*   ", "    ")))
    
    ## trunctuate the correlation matrix to two decimal
    R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
    
    ## build a new matrix that includes the correlations with their apropriate stars
    Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
    diag(Rnew) <- paste(diag(R), " ", sep="")
    rownames(Rnew) <- colnames(x)
    colnames(Rnew) <- paste(colnames(x), "", sep="")
    
    ## remove upper triangle of correlation matrix
    if(removeTriangle[1]=="upper"){
      Rnew <- as.matrix(Rnew)
      Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove lower triangle of correlation matrix
    else if(removeTriangle[1]=="lower"){
      Rnew <- as.matrix(Rnew)
      Rnew[lower.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    else if(removeTriangle[1]=="none"){
      Rnew <- as.matrix(Rnew)
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove last column and return the correlation matrix
    Rnew <- cbind(Rnew[1:length(Rnew)-1])
    if (result[1]=="none") return(Rnew)
    else{
      if(result[1]=="html") print(xtable(Rnew), type="html")
      else print(xtable(Rnew), type="latex") 
    }
} 
library(kableExtra)

# delete non numeric column (t1inno)
comp_df <- dplyr::select(comp_df, -matches("t1inno"))

corstar <- data.frame(corstars(comp_df, removeTriangle = "none", result="none"))

```

``` {r corr_table2, include = T, echo = F}
corstar %>%
  DT::datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = c('excel', "csv"),
                   pageLength = 35,
                  lengthMenu = c(25, 50, 75, 94)))

```

# LPA

```{r}
library(missForest)
library(tidyLPA)
## Selected Scales: t1netw, t1cconf
LPA_df = comp_df %>% dplyr::select(t1chal, t1threat)

# estimate profiles
LPA <- LPA_df %>% estimate_profiles(n_profiles = 1:5, models = 1, package = "mplus")
LPA
compare_lpa <- compare_solutions(LPA, statistics = c("BIC", "AIC", "Entropy"))
LPA_2 <- LPA_df %>% estimate_profiles(n_profiles = 2, models = 1, package = "mplus")
plot_profiles(LPA_2, to_center = T)

# Compare BIC
library(mclust)
clustering <- LPA_df %>%
  na.omit() %>%
  mutate_all(list(scale))
BIC <- mclustBIC(clustering)
plot(BIC)

# Compute ICL
LPA_df_nona <- LPA_df %>%
  na.omit()
ICL <- mclustICL(LPA_df_nona)

# Get LRT
LRT <- mclustBootstrapLRT(LPA_df_nona, modelName = "EEI")
LRT

# get data and fit 
data_lpa <- get_data(LPA)
fit_lpa <- get_fit(LPA)


fit_lpa_kable <- knitr::kable(fit_lpa, escape=FALSE, digits = 2, format = "html", booktabs = TRUE, caption = "Fit LPA solutions") %>%
   kable_styling(position = 'left', full_width = F)

fit_lpa_kable

```


## Normal 3 step

### Step 1

```{r}
library(MplusAutomation)
step1 <- mplusObject(TITLE = "LPA Appraisals;",
VARIABLE =
"usevar = t1chal t1threat;
CLASSES = c(2);
AUXILIARY = t2explor t2accri t2gopro t2learn t2vita;",
ANALYSIS  ="TYPE = MIXTURE;",
SAVEDATA = "FILE = man3step2_appraisal.dat;
	SAVE = CPROB;
Missflag= 999;",           
OUTPUT =   "sampstat residual tech11 tech14",
usevariables = colnames(comp_df),
rdata = comp_df)
     

step1_fit <- mplusModeler(step1,
                            dataout = "Step1_3step.dat",
                            modelout= "Step1_3step.inp",
                            check=TRUE, run = TRUE, hashfilename = FALSE)
step1_fit
```

### Step 2

```{r}
# Step 2
logit_cprobs <- as.data.frame(step1_fit[["results"]]
                                       [["class_counts"]]
                                       [["logitProbs.mostLikely"]]) #Extract logits for the classification probabilities for the most likely latent class

savedata <- as.data.frame(step1_fit[["results"]]
                                   [["savedata"]]) #Extract saved dataset which is part of the mplusObject “step1_10_fit”

colnames(savedata)[colnames(savedata)=="C"] <- "N" #Rename the column in savedata named “C” and change to “N”

library(glue)
step2  <- mplusObject(
  TITLE = "Step2 - 3step", 
  
  VARIABLE = 
 "nominal=N;
  USEVAR = n;
  missing are all (999); 
  classes = c(2); ",
  
  ANALYSIS = 
 "estimator = mlr; 
  type = mixture; 
  starts = 0;",
  
  MODEL = 
    glue(
 "%C#1%
  [n#1@{logit_cprobs[1,1]}];
  
  %C#2%
  [n#1@{logit_cprobs[2,1]}];"),
 
  usevariables = colnames(savedata), 
  rdata = savedata)

step2_fit <- mplusModeler(step2, 
                            dataout= "Step2_3step.dat", 
                            modelout= "Step2_3step.inp", 
                            check=TRUE, run = TRUE, hashfilename = FALSE)

step2_fit
```

### Step 3

```{r}
step3  <- mplusObject(
  TITLE = "Step3 - 3step", 
  
  VARIABLE = 
 "nominal=n;
  missing are all (999);
  classes = c(2);
  
  usevar = n t2explor t2accri t2gopro t2learn t2vita;",
  
  ANALYSIS = 
 "estimator = mlr; 
  type = mixture; 
  starts = 0;",
  
  MODEL =
  glue(
 " %OVERALL%

    %C#1%
  [n#1@{logit_cprobs[1,1]}];
  
  [t2explor](e1);    ! conditional distal mean 
  t2explor;          ! conditional distal variance (freely estimated)
  
   [t2accri](a1);    ! conditional distal mean 
  t2accri;          ! conditional distal variance (freely estimated)
  
  [t2gopro](g1);    ! conditional distal mean 
  t2gopro;          ! conditional distal variance (freely estimated)
  
  [t2learn](l1);    ! conditional distal mean 
  t2learn;          ! conditional distal variance (freely estimated)
  
  [t2vita](v1);    ! conditional distal mean 
  t2vita;          ! conditional distal variance (freely estimated)
  

  %C#2%
  [n#1@{logit_cprobs[2,1]}];
  
  [t2explor](e2);
  t2explor;
  
   [t2accri](a2);    ! conditional distal mean 
  t2accri;        ! conditional distal variance (freely estimated)
   
    [t2gopro](g2);
  t2gopro;

   [t2learn](l2);
  t2learn;
 
   [t2vita](v2);
  t2vita;"),
 
  
  MODELCONSTRAINT = 
   "New (diff_e_12 diff_a_12 diff_g_12 diff_l_12 diff_v_12);
    diff_e_12 = e1-e2;  ! test pairwise distal mean differences,
   diff_a_12 = a1-a2;
 diff_g_12 = g1-g2;
 diff_l_12 = l1-l2;
 diff_v_12 = v1-v2;",
 
  MODELTEST = "     ! omnibus test of distal means
    e1=e2;
 a1=a2;
 g1=g2;
 l1=l2;
 v1=v2;",
 OUTPUT =   "sampstat residual tech11 tech14;", 
  rdata = savedata)

step3_fit <- mplusModeler(step3,
               dataout= "Step3_3step.dat", 
               modelout="Step3_3step.inp", 
               check=TRUE, run = TRUE, hashfilename = FALSE)

step3_fit
```

## BCH

### Step 1

```{r}
library(MplusAutomation)
step1 <- mplusObject(TITLE = "BCH Step 1;",
VARIABLE =
"usevar = t1chal t1threat;
CLASSES = c(2);
AUXILIARY = t2explor t2accri t2gopro t2learn t2vita;",
ANALYSIS  ="TYPE = MIXTURE;",
MODEL = "%overall%
%C#1%
[t1chal t1threat*-1];
%C#2%
[t1chal t1threat*1];",
SAVEDATA = "FILE = file=2.dat; save=bch;
Missflag= 999;",           
OUTPUT =   "sampstat residual tech11 tech14",
usevariables = colnames(comp_df),
rdata = comp_df)
     

step1_fit <- mplusModeler(step1,
                            dataout = "Step1_3step.dat",
                            modelout= "Step1_3step.inp",
                            check=TRUE, run = TRUE, hashfilename = FALSE)
step1_fit
```

### Step 2

```{r}
savedata <- as.data.frame(step1_fit[["results"]]
                                   [["savedata"]])
```


### Step 3

```{r}
step3  <- mplusObject(
  TITLE = "BCH step 3", 
  
  VARIABLE = 
 "missing are all (999);
  classes = c(2);
  usevar =  t2explor t2accri t2gopro t2learn t2vita BCHW1 BCHW2;
 training = BCHW1-BCHW2(bch);",
  
  ANALYSIS = 
 "estimator = mlr; 
  type = mixture; 
  starts = 0;",
  
  MODEL =
  glue(
 " %OVERALL%

    %C#1%
  [t2explor](e1);    ! conditional distal mean 
  t2explor;          ! conditional distal variance (freely estimated)
  
   [t2accri](a1);    ! conditional distal mean 
  t2accri;          ! conditional distal variance (freely estimated)
  
  [t2gopro](g1);    ! conditional distal mean 
  t2gopro;          ! conditional distal variance (freely estimated)
  
  [t2learn](l1);    ! conditional distal mean 
  t2learn;          ! conditional distal variance (freely estimated)
  
  [t2vita](v1);    ! conditional distal mean 
  t2vita;          ! conditional distal variance (freely estimated)
  

  %C#2%
  [t2explor](e2);
  t2explor;
  
   [t2accri](a2);    ! conditional distal mean 
  t2accri;        ! conditional distal variance (freely estimated)
   
    [t2gopro](g2);
  t2gopro;

   [t2learn](l2);
  t2learn;
 
   [t2vita](v2);
  t2vita;"),
 
  
  MODELCONSTRAINT = 
   "New (diff_e_12 diff_a_12 diff_g_12 diff_l_12 diff_v_12);
    diff_e_12 = e1-e2;  ! test pairwise distal mean differences,
   diff_a_12 = a1-a2;
 diff_g_12 = g1-g2;
 diff_l_12 = l1-l2;
 diff_v_12 = v1-v2;",
 
  MODELTEST = "     ! omnibus test of distal means
    e1=e2;
 a1=a2;
 g1=g2;
 l1=l2;
 v1=v2;",
 OUTPUT =   "sampstat residual tech11 tech14;", 
 usevariables = colnames(savedata),
  rdata = savedata)

step3_fit <- mplusModeler(step3,
               dataout= "Step3_3step.dat", 
               modelout="Step3_3step.inp", 
               check=TRUE, run = TRUE, hashfilename = FALSE)

step3_fit
```




